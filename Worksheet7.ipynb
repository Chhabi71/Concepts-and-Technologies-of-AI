{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Classification Task (Breast Cancer)"
      ],
      "metadata": {
        "id": "dDnlfT0kInFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Load and Split Dataset"
      ],
      "metadata": {
        "id": "J5FyS7C9IoUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcn_OgXoGooA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and splitdataset\n",
        "X_cls, y_cls = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
        "    X_cls, y_cls, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "hVA9ZF29HE_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Complete all the Task"
      ],
      "metadata": {
        "id": "WbQ2zUjfI_n9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "– Step 1: Baseline Model (No Regularization) Build a Logistic Regression model without\n",
        "specifying any regularization (default settings)."
      ],
      "metadata": {
        "id": "gW_cqBVzJDtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = LogisticRegression(max_iter=10000)\n",
        "baseline.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "print(\"Baseline coefficients:\\n\", baseline.coef_)\n",
        "print(\"Baseline train acc:\", accuracy_score(y_train_cls, baseline.predict(X_train_cls)))\n",
        "print(\"Baseline test acc:\", accuracy_score(y_test_cls, baseline.predict(X_test_cls)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBvExcS9HVIF",
        "outputId": "88c18b4b-84e1-4138-e223-430e814c1f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline coefficients:\n",
            " [[ 1.0274368   0.22145051 -0.36213488  0.0254667  -0.15623532 -0.23771256\n",
            "  -0.53255786 -0.28369224 -0.22668189 -0.03649446 -0.09710208  1.3705667\n",
            "  -0.18140942 -0.08719575 -0.02245523  0.04736092 -0.04294784 -0.03240188\n",
            "  -0.03473732  0.01160522  0.11165329 -0.50887722 -0.01555395 -0.016857\n",
            "  -0.30773117 -0.77270908 -1.42859535 -0.51092923 -0.74689363 -0.10094404]]\n",
            "Baseline train acc: 0.9582417582417583\n",
            "Baseline test acc: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "– Step 2: Hyperparameter Tuning Use GridSearchCV or RandomizedSearchCV to tune\n",
        "hyperparameters for logistic regression models with regularization."
      ],
      "metadata": {
        "id": "gjsThNMzJIQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"penalty\": [\"l1\", \"l2\"],\n",
        "    \"C\": np.logspace(-3, 3, 7),\n",
        "    \"solver\": [\"liblinear\"],  # supports both l1 and l2\n",
        "}\n",
        "\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "grid = GridSearchCV(logreg, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "print(\"\\nBest params:\", grid.best_params_)\n",
        "print(\"Best CV acc:\", grid.best_score_)\n",
        "print(\"Test acc (best model):\",\n",
        "      accuracy_score(y_test_cls, grid.best_estimator_.predict(X_test_cls)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGeO-jIgHg5B",
        "outputId": "1729e76c-cfe4-4d63-d62b-30ffb29503da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best params: {'C': np.float64(100.0), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best CV acc: 0.9670329670329672\n",
            "Test acc (best model): 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Regularization Experiments (L1 vs L2)"
      ],
      "metadata": {
        "id": "4Wn6yd4cMHpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_C = grid.best_params_[\"C\"]\n",
        "\n",
        "# L1 model\n",
        "logreg_l1 = LogisticRegression(penalty=\"l1\", C=best_C,\n",
        "                               solver=\"liblinear\", max_iter=10000)\n",
        "logreg_l1.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "print(\"\\nL1 coefficients:\\n\", logreg_l1.coef_)\n",
        "print(\"L1 zero coeffs:\", np.sum(logreg_l1.coef_ == 0))\n",
        "print(\"L1 train acc:\", accuracy_score(y_train_cls, logreg_l1.predict(X_train_cls)))\n",
        "print(\"L1 test acc:\", accuracy_score(y_test_cls, logreg_l1.predict(X_test_cls)))\n",
        "\n",
        "# L2 model\n",
        "logreg_l2 = LogisticRegression(penalty=\"l2\", C=best_C,\n",
        "                               solver=\"liblinear\", max_iter=10000)\n",
        "logreg_l2.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "print(\"\\nL2 coefficients:\\n\", logreg_l2.coef_)\n",
        "print(\"L2 zero coeffs:\", np.sum(logreg_l2.coef_ == 0))\n",
        "print(\"L2 train acc:\", accuracy_score(y_train_cls, logreg_l2.predict(X_train_cls)))\n",
        "print(\"L2 test acc:\", accuracy_score(y_test_cls, logreg_l2.predict(X_test_cls)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpifxFH5Hs8r",
        "outputId": "4ed27f3d-d2bd-4151-9a0a-3bc4665544a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "L1 coefficients:\n",
            " [[ 7.34927717e-01 -1.08501794e-01  9.96469531e-02 -2.28659494e-03\n",
            "   0.00000000e+00  4.71851510e+01 -1.19973662e+01 -1.36151622e+02\n",
            "   1.97539540e+01  0.00000000e+00  0.00000000e+00  1.73053319e+00\n",
            "   0.00000000e+00 -1.97605105e-01  0.00000000e+00  0.00000000e+00\n",
            "   5.01549973e+01  0.00000000e+00  1.88958734e+01  0.00000000e+00\n",
            "   2.10181738e-01 -4.38559195e-01  5.75797710e-02 -2.10586499e-02\n",
            "  -2.16155684e+01  7.96286116e+00 -1.45988415e+01 -2.53019436e+01\n",
            "  -2.53549004e+01  0.00000000e+00]]\n",
            "L1 zero coeffs: 9\n",
            "L1 train acc: 0.989010989010989\n",
            "L1 test acc: 0.9824561403508771\n",
            "\n",
            "L2 coefficients:\n",
            " [[ 5.40272741  0.26573732 -0.52651203 -0.02095479 -2.29922151 -0.2169419\n",
            "  -3.56980218 -5.0110607  -2.26418385  0.36762747 -0.58036525  3.84169255\n",
            "  -0.63875637 -0.10714305 -0.40591246  3.57237002  4.36577514 -0.26636925\n",
            "   0.39354765  0.62630698 -0.20718582 -0.68999884  0.17661962 -0.01813087\n",
            "  -4.67716843 -0.0140846  -4.46493229 -7.61271125 -6.83571871  0.57463274]]\n",
            "L2 zero coeffs: 0\n",
            "L2 train acc: 0.9692307692307692\n",
            "L2 test acc: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Regression Task (California Housing)"
      ],
      "metadata": {
        "id": "3GHmHjjoOCyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Load and Split Dataset"
      ],
      "metadata": {
        "id": "rUt6X2RSOGXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "mIun0lL6H4zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load California Housing dataset and split 80/20\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B6FcH7eLjbJ",
        "outputId": "c9c93b93-87e9-4e66-f778-9d33a38d73fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data folder: /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Complete all the Task\n",
        "\n",
        "• Regression Task (California Housing):"
      ],
      "metadata": {
        "id": "euB0Dv7oOKrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "– Step 1: Baseline Model (No Regularization) Build a Linear Regression model without\n",
        "any regularization."
      ],
      "metadata": {
        "id": "9bYlciSGONJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Linear Regression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Baseline Linear Regression\")\n",
        "print(\"Coefficients:\", lin_reg.coef_)\n",
        "print(\"Intercept:\", lin_reg.intercept_)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = lin_reg.predict(X_train)\n",
        "y_test_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# MSE on train and test\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "JYxapSJEN2i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "– Step 2: Hyperparameter Tuning Use GridSearchCV or RandomizedSearchCV to tune\n",
        "hyperparameters for Ridge and Lasso regression models."
      ],
      "metadata": {
        "id": "kKid4RgmOPnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alpha grid for Ridge and Lasso\n",
        "alpha_grid = np.logspace(-3, 0, 13)  # 0.001 to 1\n",
        "\n",
        "ridge = Ridge(random_state=42)\n",
        "lasso = Lasso(random_state=42, max_iter=10000)\n",
        "\n",
        "ridge_cv = GridSearchCV(\n",
        "    ridge,\n",
        "    {\"alpha\": alpha_grid},\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "lasso_cv = GridSearchCV(\n",
        "    lasso,\n",
        "    {\"alpha\": alpha_grid},\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nHyperparameter Tuning Results\")\n",
        "print(\"Best Ridge alpha:\", ridge_cv.best_params_[\"alpha\"])\n",
        "print(\"Best Ridge CV MSE:\", -ridge_cv.best_score_)\n",
        "print(\"Best Lasso alpha:\", lasso_cv.best_params_[\"alpha\"])\n",
        "print(\"Best Lasso CV MSE:\", -lasso_cv.best_score_)\n"
      ],
      "metadata": {
        "id": "6cFj8_HcN-5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "– Step 3: Regularization Experiments (L1 vs L2) Train L1 (Lasso) and L2 (Ridge) regres-\n",
        "sion models using the optimal hyperparameters."
      ],
      "metadata": {
        "id": "uQ2lIz6aOSnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best estimators from GridSearchCV\n",
        "best_ridge = ridge_cv.best_estimator_\n",
        "best_lasso = lasso_cv.best_estimator_\n",
        "\n",
        "# Predictions with best Ridge and Lasso\n",
        "ridge_train_pred = best_ridge.predict(X_train)\n",
        "ridge_test_pred = best_ridge.predict(X_test)\n",
        "\n",
        "lasso_train_pred = best_lasso.predict(X_train)\n",
        "lasso_test_pred = best_lasso.predict(X_test)\n",
        "\n",
        "print(\"\\nRidge (L2) with best alpha\")\n",
        "print(\"Coefficients:\", best_ridge.coef_)\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, ridge_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, ridge_test_pred))\n",
        "\n",
        "print(\"\\nLasso (L1) with best alpha\")\n",
        "print(\"Coefficients:\", best_lasso.coef_)\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, lasso_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, lasso_test_pred))\n",
        "\n",
        "print(\"\\nNumber of zero coefficients in Lasso:\", np.sum(best_lasso.coef_ == 0))\n",
        "print(\"Number of zero coefficients in Ridge:\", np.sum(best_ridge.coef_ == 0))\n"
      ],
      "metadata": {
        "id": "gF4SHzWrOAKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}